name: "00 - Bootstrap: Enterprise Infrastructure"

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to bootstrap'
        required: true
        type: choice
        options: [dev, qa, staging, prod, all]
        default: 'dev'

env:
  AWS_REGION: us-west-2
  TENANT: opsera
  HUB_CLUSTER: argocd-usw2
  SPOKE_CLUSTER: opsera-usw2-np

permissions:
  contents: read
  id-token: write

jobs:
  preflight:
    name: "01 - Pre-flight Checks"
    runs-on: ubuntu-latest
    outputs:
      hub_exists: ${{ steps.clusters.outputs.hub_exists }}
      spoke_exists: ${{ steps.clusters.outputs.spoke_exists }}
      spoke_registered: ${{ steps.clusters.outputs.spoke_registered }}
      aws_account: ${{ steps.clusters.outputs.aws_account }}
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/v1.28.0/bin/linux/amd64/kubectl"
          chmod +x kubectl && sudo mv kubectl /usr/local/bin/
      - name: Check EKS Clusters & Spoke Registration
        id: clusters
        run: |
          echo "## 01 - Pre-flight Checks" >> $GITHUB_STEP_SUMMARY
          echo "| Check | Result |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          echo "aws_account=${AWS_ACCOUNT_ID}" >> $GITHUB_OUTPUT
          echo "| AWS Account | \`${AWS_ACCOUNT_ID}\` |" >> $GITHUB_STEP_SUMMARY
          if aws eks describe-cluster --name ${{ env.HUB_CLUSTER }} --region ${{ env.AWS_REGION }} &>/dev/null; then
            echo "hub_exists=true" >> $GITHUB_OUTPUT
            echo "| Hub Cluster | âœ… \`${{ env.HUB_CLUSTER }}\` |" >> $GITHUB_STEP_SUMMARY
          else
            echo "hub_exists=false" >> $GITHUB_OUTPUT
            echo "| Hub Cluster | âŒ Not found - run EKS bootstrap first |" >> $GITHUB_STEP_SUMMARY
          fi
          if aws eks describe-cluster --name ${{ env.SPOKE_CLUSTER }} --region ${{ env.AWS_REGION }} &>/dev/null; then
            echo "spoke_exists=true" >> $GITHUB_OUTPUT
            echo "| Spoke Cluster | âœ… \`${{ env.SPOKE_CLUSTER }}\` |" >> $GITHUB_STEP_SUMMARY
          else
            echo "spoke_exists=false" >> $GITHUB_OUTPUT
            echo "| Spoke Cluster | âŒ Not found |" >> $GITHUB_STEP_SUMMARY
          fi
          if aws eks describe-cluster --name ${{ env.HUB_CLUSTER }} &>/dev/null; then
            aws eks update-kubeconfig --name ${{ env.HUB_CLUSTER }} --region ${{ env.AWS_REGION }} --alias hub
            if kubectl --context hub get secret "cluster-${{ env.SPOKE_CLUSTER }}" -n argocd &>/dev/null; then
              echo "spoke_registered=true" >> $GITHUB_OUTPUT
              echo "| Spoke in ArgoCD | âœ… Registered |" >> $GITHUB_STEP_SUMMARY
            else
              echo "spoke_registered=false" >> $GITHUB_OUTPUT
              echo "| Spoke in ArgoCD | âš ï¸ Not registered |" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "spoke_registered=false" >> $GITHUB_OUTPUT
          fi

  argocd-setup:
    name: "03 - ArgoCD Configuration"
    runs-on: ubuntu-latest
    needs: [preflight]
    if: needs.preflight.outputs.hub_exists == 'true' && needs.preflight.outputs.spoke_exists == 'true' && needs.preflight.outputs.spoke_registered != 'true'
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/v1.28.0/bin/linux/amd64/kubectl"
          chmod +x kubectl && sudo mv kubectl /usr/local/bin/
      - name: Connect to Hub and Spoke Clusters
        run: |
          aws eks update-kubeconfig --name ${{ env.HUB_CLUSTER }} --region ${{ env.AWS_REGION }} --alias hub
          aws eks update-kubeconfig --name ${{ env.SPOKE_CLUSTER }} --region ${{ env.AWS_REGION }} --alias spoke
      - name: Register Spoke Cluster in ArgoCD (Idempotent - RULE 238)
        run: |
          echo "## 03 - ArgoCD Cluster Registration" >> $GITHUB_STEP_SUMMARY
          SPOKE_ENDPOINT=$(aws eks describe-cluster --name ${{ env.SPOKE_CLUSTER }} --region ${{ env.AWS_REGION }} --query 'cluster.endpoint' --output text)
          SPOKE_CA=$(aws eks describe-cluster --name ${{ env.SPOKE_CLUSTER }} --region ${{ env.AWS_REGION }} --query 'cluster.certificateAuthority.data' --output text)
          kubectl --context spoke create namespace argocd-manager 2>/dev/null || true
          cat <<EOF | kubectl --context spoke apply -f -
          apiVersion: v1
          kind: ServiceAccount
          metadata:
            name: argocd-manager
            namespace: argocd-manager
          ---
          apiVersion: v1
          kind: Secret
          metadata:
            name: argocd-manager-token
            namespace: argocd-manager
            annotations:
              kubernetes.io/service-account.name: argocd-manager
          type: kubernetes.io/service-account-token
          EOF
          cat <<EOF | kubectl --context spoke replace --force -f -
          apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRoleBinding
          metadata:
            name: argocd-manager-role-binding
          roleRef:
            apiGroup: rbac.authorization.k8s.io
            kind: ClusterRole
            name: cluster-admin
          subjects:
            - kind: ServiceAccount
              name: argocd-manager
              namespace: argocd-manager
          EOF
          sleep 5
          SA_TOKEN=$(kubectl --context spoke get secret argocd-manager-token -n argocd-manager -o jsonpath='{.data.token}' | base64 -d)
          cat <<EOF | kubectl --context hub apply -f -
          apiVersion: v1
          kind: Secret
          metadata:
            name: cluster-${{ env.SPOKE_CLUSTER }}
            namespace: argocd
            labels:
              argocd.argoproj.io/secret-type: cluster
          type: Opaque
          stringData:
            name: "${{ env.SPOKE_CLUSTER }}"
            server: "${SPOKE_ENDPOINT}"
            config: |
              {"bearerToken":"${SA_TOKEN}","tlsClientConfig":{"insecure":false,"caData":"${SPOKE_CA}"}}
          EOF
          echo "| \`${{ env.SPOKE_CLUSTER }}\` | ðŸ†• Registered |" >> $GITHUB_STEP_SUMMARY

  k8s-setup:
    name: "04 - Kubernetes Setup"
    runs-on: ubuntu-latest
    needs: [preflight, argocd-setup]
    if: always() && needs.preflight.outputs.spoke_exists == 'true'
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/v1.28.0/bin/linux/amd64/kubectl"
          chmod +x kubectl && sudo mv kubectl /usr/local/bin/
      - name: Setup Namespaces (Idempotent)
        run: |
          aws eks update-kubeconfig --name ${{ env.SPOKE_CLUSTER }} --region ${{ env.AWS_REGION }} --alias spoke
          echo "## 04 - Kubernetes Namespaces" >> $GITHUB_STEP_SUMMARY
          echo "| Namespace | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "Shared infrastructure namespaces verified"
          echo "| Shared infra | âœ… Ready |" >> $GITHUB_STEP_SUMMARY

  verify:
    name: "05 - Verification"
    runs-on: ubuntu-latest
    needs: [preflight, argocd-setup, k8s-setup]
    if: always()
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/v1.28.0/bin/linux/amd64/kubectl"
          chmod +x kubectl && sudo mv kubectl /usr/local/bin/
      - name: Verify All Components
        run: |
          echo "## 05 - Infrastructure Verification" >> $GITHUB_STEP_SUMMARY
          echo "| Component | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          if aws eks describe-cluster --name ${{ env.HUB_CLUSTER }} &>/dev/null; then
            aws eks update-kubeconfig --name ${{ env.HUB_CLUSTER }} --region ${{ env.AWS_REGION }} --alias hub
            kubectl --context hub get nodes &>/dev/null && \
              echo "| Hub Cluster | âœ… Accessible |" >> $GITHUB_STEP_SUMMARY || \
              echo "| Hub Cluster | âŒ Not accessible |" >> $GITHUB_STEP_SUMMARY
            kubectl --context hub get secret "cluster-${{ env.SPOKE_CLUSTER }}" -n argocd &>/dev/null && \
              echo "| Spoke Registration | âœ… Registered |" >> $GITHUB_STEP_SUMMARY || \
              echo "| Spoke Registration | âš ï¸ Not registered |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸš€ Next Steps:" >> $GITHUB_STEP_SUMMARY
          echo "- Run app-specific bootstrap: \`00-bootstrap-test-1.yaml\`" >> $GITHUB_STEP_SUMMARY
          echo "- Then trigger CI/CD: \`cicd-test-1-dev.yaml\`" >> $GITHUB_STEP_SUMMARY
